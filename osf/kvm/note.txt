make EXTRA_CFLAGS=-I$(xxx)



IRQ和Softirq上下文：
抢占：
原子上下文和可睡眠环境：

IRQ和Softirq：

IRQ来了以后，这个引脚的中断会被一直占用直到完成。


1：CPU出发中断，并且本CPU中断被禁用
2：保存上下文，在IDT中找到中断函数
3：IRQ ACK ->出发EOI，end of interrupt  这里就是中断上半部与下半部的分界点。
4：运行中断处理函数
5：回复中断

问题：
1）如果中断函数中需要做的好事操作比较多：
会将CPU的中断一直保存禁止状态，可能导致其他中断被丢失
2）softirq因此而生，他将中断操作分两部分
一部分是在禁止中断中快速的完成，被称为上半部
另一部分可以在打开中断情况下完成，这一部分相对于第一部分要耗时，被称为下半部

网卡在dma中取包，需要禁用中断，是防止在取包的时候防止有其他包到来  

do_IRQ：是找寻所有相应中断号处理函数，并调用这些函数的入口；

do_IRQ->irq_exit->invoke_softirq->__do_softirq   通过这个流程来了解，中断的打开和关闭时机


抢占：
简言之，抢占就是当将当前的调度实体（进程或线程）切换出CPU然后当下一个调度实体切换上CPU
抢占的时机：
1）主动放弃CPU（调用 schedule()）
2）从中断/异常处理退出时
3）自定义的某些点（cond_resched())
cond_resched的例子：

kvm_mmu_sync_roots-> mmu_sync_roots-> mmu_sync_children->__code_resched_lock

原子上下文和可睡眠环境：
1）原子上下文即不可被切换出CPU的状态，也即不可睡眠状态，与可睡眠环境相反
2）原子上下文包括：
    在处理IRQ的时候
    在处理softirq的时候
    在抢占被禁用的时候   
与原子上下文相关的code
    每一个进程（包括线程）都维护者一个preempt_count:
    #define preemt_count() (current_thread_info()->preempt_count
    如果进程切换了？之前的进程计数是不是会被丢弃？   只要这个计数不为零，就不能被切换；
    perrmpt_count的组织
    0-7bit->preemption count
    8-15bit->softirqcount
    16-25:hardirq count
    26bit:NMI
    27bit:
    28-31bit:preempt_cative
    
    #define __irq_enter()
    #define __irq_exit()
    #define __nmi_enter()
    #deinfe __nmi_exit()
    peermpt_count_add()
    peermpt_count_add()
    peermpt_count_sub()
    
    
    #define sched_preempt_enable_no_resched()
    #define preempt_enable_no_resched()
    #define preemt_enable()
    #define preempt_disable()
    
    #define in_atomic():检测是否是原子环境;

内核同步：
1：锁
2：原子操作
3：内存屏障
4：代码分析：锁的实现

锁：
1）用于串行操作，避免竞争
2）两种主要类型
    -不可睡眠的锁
    -可睡眠的锁
不可睡眠的锁：
1）自旋锁
    -所谓自旋锁，就是资源得不到满足时候，就一直去探测资源。
    -自旋锁会自动关闭当前CPU的抢占
    -所以，在持有自旋锁后不应该有睡眠的操作。例如：a）分配内存的时候，如果内存不足，可能就需要当前进程睡眠，方便mm后台回收内存；b）当持有自旋锁的时候，试图去获得可睡眠的锁也是不可以的。
2）APIs
    初始化：
        编译时候初始化：DEFINE_SPINLOCK()
        运行时候初始化：spin_lock_init()
    持有锁与释放锁
        spin_lock()/spin_unlock

自旋锁的变体
    禁用中断+自旋锁
        spin_lock_irq()/spin_unlck_irq()
        spin_lock_irqsave()/spin_unlock_irqrestore()
    禁止下半部+自旋锁
        spin_lock_bh()/spin_unlock__bh()    
读写自旋锁：
    读写锁的一种，用于读操作非常频繁而写操作频率很低，他可以降低读侧开销， 
允许读侧并行，但提高写测开销。
    APIs
        初始化：DEFINE_RWLOCK()/rwlock_init()
        read_lock()/read_unlock();write_lock()
        /write_lock()
        irqsave...等等变体与spinlock类似
RCU（也是不可睡眠锁）        
    
问题？1、抢占禁用的时候，能否被中断
      2、为什么要单独设置中断上下文?
      
答疑的笔记：
模块签名是3.7kernel里面新增的功能；

与数字签名相关的几个配置选项：
CONFIG_MODULE_SIG_FORCE
CONFIG_MODULE_SIG_ALL
CONFIG_SIG_SHA1到CONFIG_SIG_SHA512
如何手动签名?

a)内核实现一个设备供用户空间来操作.
b)netlink
c)扩展系统调用


问题：就是把第一个模块的符号表拷贝到第二个模块里头，是不是仅仅为了 不让编译时候提示找不到符号的警告？
1)不警告
2)产生模块依赖关系，让modprob进行模块依赖测试；

insmod 具体做的什么 工作？
用户空间会调用 load_module()，然后解析ELF文件，然后解析各个段（代码段.数据段等等）映射到相应的地方，能够被调用； 
insmod => 解释ELF， 加载ELF到对应的位/生成符号表
debug 的ELF 和 Release的ELF 主要区别是什么?readelf 
debug 是打开了gcc -g的调试命令。就含有了函数的符号表，以及一些调用关系，都能方便找到
relese 为了考虑到cache的优化使用和image的大小，都会省略掉debug info
 
preempt的每个位数都是预留好的，是否可能发生溢出呢？
1：如果出现bug可能溢出；正常情况下是不会溢出的；
2：例子：内核社区的一个例子：有人报告了一个BUG，提示SOFTIRQ 

COUNT被溢出了，因为软中断执行的时间过长，导致嵌套次数过多。
最后分析得到的结论是，RCU的CALLBACK太多了。RCU的CALLBACK允许被迁移可以迁移到其他CPU。

软中断的线程是每次报软中断都会执行的吗，还是只在软中断执行时间过久时才会启动？
在软中断繁忙时被启动
有参数可以设定为一直用线程来处理软中断

用户空间可以使用自旋锁吗？
不可以

Preemption count、softirq count、hadrdirq cout、nmi的作用分别是？
Preemption count = 每次禁用抢占的时候+1、softirq count = 每次执行软中断的时候+1、hadrdirq cout = 每次执行中断的时候+1、nmi= 每次发生NMI的时候+1


有几种是 睡眠锁 ？
睡眠锁： MUTEX， 还有RCU配置成可抢占的时候

Preemption count、softirq count、hadrdirq cout、nmi 有可能同时发生吗？
不能同时，但可以连续， 比如hardirq -> softirq -> PREE. 不可能同时增加
 
在编写 模块的时候 不会被调用的函数 会被编译到模块中去吗？有编译开关吗？
按照内核的优化级别的话，可以自动丢掉的。

LWN.net会对每个内核的改动说明;
知道内核差异：
1：mail list
2：release changelog

https://www.ibm.com/developerworks/cn/linux/l-cn-ftrace/
ftrace是一个比较好的料及内核的工具；


rcu和内存屏障？

 内核的一个基本原则就是：在中断或者说原子上下文中，内核不能访问用户空间，而且内核是不能睡眠的。也就是说在这种情况下，内核是不能调用有可能引起睡眠的任何函数。一般来讲原子上下文指的是在中断或软中断中，以及在持有自旋锁的时候。
 
 
 不可睡眠锁：
 
 kthread_should_stop()是用来判断，是否这个进程被执行了kthread_stop()
 在线程中可以这么使用：
     while(!kthread_should_stop()){
         msleep(10); //delay.h
     }
可睡眠锁：

RCU
读写锁；写端延迟较大；
1）老版本中写着的时延相对要大一些，所以在实时性要求较高的场景，在新的版本中增加了一个配置选项。
2）CONFIG_PREEMPT_RCU 配置选项是来配置，读是否被抢占；
3） rcu的读者基本无需枷锁，但是他吧所得时间放在了写的时候；
4） note：
    只用来保护指针，因为指针的引用和指针的赋值在所有平台都是不可中断的（即为原子操作）
	如果写着比较多，不要使用RCU
	CONFIG_PREEMPT_RCU用于real time很强的场合，为了更好的代码移植，最好不要这么做。尽可能的不要将rcu用于可睡眠的场合（为什么？？）
RCU的使用：
    用rcu保护的数据需要 在之前增加 __rcu
	例如：void __rcu *data;
    读者：
        1、使用RCU_READ_LOCK()来进入读测
        2、使用rcu_derference()来获取指针对应的资源
        3、使用rcu_read_unlock()来推出读侧
    写着：
        1、如果有多个写端，需要写端自己做同步（例如使用spinlock）
        2、使用rcu_assign_pointer()来更新指针
        3、使用call_rcu()/synchronize_rcu()来释放旧指针对应的资源		
        
	使用：
	    call_rcu()和synchronize_rcu()的区别
		-call_rcu()用来释放的工作交给后台，可以快速的返回，不会导致睡眠
		-synchronize_rcu()会等待所有读者退出后再返回，会导致睡眠
	rcu的变体：
	    defer              protect
	a. synchronize_rcu()      rcu_read_lock()/rcu_read_unlock()
	b. call_rcu_bh()          rcu_read_lock_bh()/rcu_read_unlock_bh()
	                          rcu_dereference_hb()
	c. synchronize_sched()    rcu_read_lock_sched() / rcu_read_unlock_sched()
	                          preempt_disable()/preempt_enable()
							  local_irq_save()/local_irq_restore()
							  hardirq enter/ hardirq exit
							  NMI enter / NMI exit
							  rcu_dereference_sched()
							  
	code事例：
	do_write(){
        rcu_assign_pointer();
        synchronize_rcu();
    
    }
    
    do_read(){
        rcu_read_lock()；
        临界区；
        rcu_read_unlock()；
    }

可睡眠锁：
    - 一次只能被一个对象所持有
	- 类似于用户间glibc中的pthread_mutext_lock一样的
	- 持有mutex后任然可以睡眠（可以被调度出去）
	
 Mutex（互斥量）
    -使用
       #include <linux/mutex.h>
     初始化：  
        -编译时初始化： DEFINE_MUTEX()
        -运行时初始化：mutex_init()
     持有锁：
	    -mutex_lock() ->在临界区不响应，任何信号（信号来了，不响应，那么信号呢？是等这个线程被唤醒后，再响应信号？还是就相当于信号丢失了？）
		-mutex_lock_interruptible()->在临界区相应信号（相应的行为？那么对中断的处理呢？mutex_lock对锁的处理呢）
		-mutex_lock_kilable()->只响应SIGKILL的信号
      释放锁
        - mutex_unlock()	 

     code实例：
     do_write(){
     
     }
     
     do_read(){
     
     } 
        
可睡眠锁：
   semaphore（信号量）
    -信号量的值可以大于1
    -持有锁时
        如果当前值为0，则睡眠，等值信号量的值变为非0
        否则，信号值的值减1
    -释放锁时
        将信号量的值加1，如果有进程等待该信号量则将其唤醒
	
   semaphore使用
     - #include <linux/semaphore.h>
     - 初始化：
        编译时初始化 DEFINE_SEMPHORE(sem)
        运行时初始化 sema_init(sem, val)
     - 持有锁
        down()
        down_interruptible()
        down_killable()
     - 释放锁
        up()    
    
    code实例：
    do_write(){
        
    }

    do_read(){
    
    }    
    
   rwsem(读写信号量)
     - 读写锁
     - 只有一个值， 空闲时为1，被使用时为0     
     
     一个临界区允许多个读端，但是只允许你哥写端
     
     -使用
        #include <linux/rwsem.h>
        初始化
           -编译时初始化 DECLARE_RWSEM()
           -运行时初始化init_rwsem()
        读者
           -持有锁 down_read()
           -释放锁 up_read()
        写者
           -持有锁 down_write()
           -释放锁 up_write()
        
        code实例
        do_write(){
        
        }
        
        do_read(){
        
        }
完成变量
    completion 用于一种显示的等待事件（与锁的区别：一个进程等待另一进程完成某个事情
     所以自己要睡眠，等待另一个事情完成后才被唤醒）
    初始化
       - 编译时初始化 DECLARE_COMPLETION()
       - 运行时初始化 init_completion()
    等待事件
       - wait_for_completion()/wait_for_complention_interruptible()/
         wait_for_completion_killable()/wait_for_completion_io()/
         wait_for_completion_xxx_timeout
    事情完成
       complete()/complete_all()
          complete()只会唤醒一个正在等待的进程而complete_all()则唤醒全部 
        #include <complete.h>
        
        code实例
        do_write(){
        
        }
        
        do_read(){
        
        }
可睡眠锁：
 -RCU （if  CONFIG_PREEMPT_RCU 如果这种配置是可睡眠的）
 -SRCU （sleepable RCU） 
    -持有 SRCU的一侧可以睡眠
    -使用同普通的RCU类似  

  -使用
      - #include <linux/srcu.h>
      初始化
       -编译时初始化 DEFINE_SRCU()/DEFINE_STATIC_SRCU()
       -运行时初始化 init_srcu_struct()
      
      读者
        获得锁 srcu_read_lock()
        获得保护的指针 srcu_dereference() //多了一个check，会check是否已经获得了srcu的锁，相对于rcu来说
        释放锁 srcu_read_unlock()
      
      写者释放旧指针 synchronize_srcu()/call_srcu()
      使用完成 cleanup_srcu_struct()      
      
      code实例
      do_write() {
         srcu_ 
      }
      
      do_read() {
          
      }
 
用户态的锁，在等待的时候，会陷入到内核，然后内核会使用futx休眠。 
禁用了中断就自动禁用抢占了
schedule的表现行为：1、内核抢占；2、主动调度；3、
调试方法：kdump
memory-barriers.txt
atomic-oprations是叫portin
http://eudyptula-challenge.org      
原子操作：
内存屏障：先网上搜搜          
      
对linux不熟悉的可以看 ftrace这个小模块，里头会有很多的简单的小模块。内核调试1)printk;2)kdump;
eric's kernel mail list:lkml kvm xen netdev

会引起睡眠的一些操作:msleep(), kmalloc()
memcpy():对于访问内核空间的页面之间的copy是不会发生睡眠的。而如果拷贝的有用户空间的可能会发生缺页，然后进入睡眠。内核空间的页面都是映射好的，所以不会睡眠。
内存访问越界：如果是kmalloc申请的那么不会睡眠，如果是vmalloc申请的可能会睡眠.


原子操作：不能被CPU和其他CPU所中断的执行指令或指令流。

CPU中原子操作的实现：
1）CPU基本的原子操作
2）LOCK前缀
3）自动带LOCK的指令
CPU平台本身可以保证的原子操作
1）读或者写一个字节（因为访问一个字节总是对齐的）
2）读或者写一个对齐的16-bit的数据
3）读或者写一个对齐的32-bit的数据
4）读或者写一个对齐的64-bit数据(64位CPU)
另外：如下两个特性仅仅在x86平台上才是有效的，而上面4个是所有平台通用的。
    1）在32-bit的数据总线上访问一块cache禁止的16数据(>=Pentium)
    2）在一个cache line中访问不对齐的16,32,64,位数据(>=P6 pamily)
LOCK前缀：
    -指令前带LOCK前缀破事CPU做独占的内存访问
    -xchg自动带有LOCK前缀
LOCK在不同CPU版本的实现
    -在较老的CPU上，产生LOCK信号以用来锁总线
    -在>=P6 family,锁cache line（是几级cache line）
LOCK前缀
 代码示例：
  cmpxchg(ptr, old, new):比较*ptr和old的值，如果相等则*ptr=new,在任何时候该函数返回ptr的初始值，因为，如果想要知道ptr的值是否被new替换，只需要检查其返回值是否与old相等。
  #define cmpxche(ptr,old,new)
        __cmpxchg(ptr,old, netw,sizeof(*(ptr))
  #define __cmpxchg(ptr, old, new, size)
     __raw_cmpxchg((ptr), (old),(new),(size), LOCK_PREFIX)

自动带LCOK前缀的指令
 a）xchg
 b）事务内存（TSX on intel）
   可以自定义一块transaction region，然后可以在区域结束的时候原子提交，如果成功提交，则其CPU可以看到该区域的所有更改，如果提交失败则撤销该区域的所有更改操作，进而转入到程序提供的abort代码（失败的场景：a.两个CPU都在对同一个事务内存操作，CPU1和CPU2，CPU1的操作是只读去事务内存的内容，CPU2是修改事务内存的内容，CPU1读取了数据后，CPU2修改了事务内存，然后CPU2提交事务的时机又早于CPU1，那么CPU1读取的是old的数据，那么这时候CPU1会发生事务提交失败；b.例如powerpc中实现的事务内存，如果在操作事务内存期间，发生了中断，那么提交的事务内存就会失败） 

Linux Kernel中的原子操作
两种主要的类型：
   -atiomic_t 的数据
   
     atatomic_t操作： 
      --include/linux/atomic.h:与平台无关的公共操作
      --include/asm/atomic.h:与平台相关的操作
     例如：
     atomic_xchg(v,new)
     atomic_cmpxchg(v,old,new)
     atomic_add_negative(i,v)
     atomic_add_unless(v,a,u)
   -bit操作
     -原子性的未操作
     -常用操作：
        set_bit(nr, *addr)
        change_bit(nr, *addr)
        test_and_set_bit(nr,*addr)
        test_and_clear_bit(nr,*addr)
        test_and_change_bit(nr, *addr)
       另外，非原子的位操作
          __set_bit(nr, *addr)
          __clear_bit(nr, *addr)
          test_bit(nr, *addr)
       说明：原子的和非原子的test_bit是同一个函数，因为对一个对齐的unsigned lang的操作是原子的。
   -其他指令
     -xchg()
     -cmpxchg()
     -cmpxchg_double()

内存屏障：
  就是强制规定内存访问次序
产生原因：
  -编译器优化
  -CPU的乱序和推测执行

消除编译器导致的乱序
  -asm volatile("":::"memory")
  -C语言中的volatile关键字
X86的内存序列
   -相同类型的操作(read vs read;write vs write)不能被乱序
      A=B=0
      cpu 0                      cpu 1
    write 1->A                 read B->R1
    write 1->B		       read A->R2
     不存在R1=1 &&R2=0
   -write不能乱序到read前面
     A=B=0
      cpu 0                     cpu1
    read A->R1                read B->R2
    write 1->B                write 1->A
     不存在R1=1 &&R2=1

   -read可能乱序到write前面
     A=B=0
      cpu 0                    cpu1
     write 1->A              write 1->B
     read B->R1              read A->R2
      存在R1=0 && R2=0
   -CPU内部内存访问允许bypass(因为写有一个buffer，也就是本cpu写入后，还没同步到内存，仅仅在自己的buffer中，别的CPU有一段时间无法安置，但是本CPU的读可以从buffer中直接读取)
     A=B=0
      cpu 0                    cpu1
     write 1->A              write 1->B
     read A->R1              read B->R3
     read B->R2              read A->R4
       存在R2 = 0 && R4=0
   -write全局可见的(在cpu0看到的写的顺序，那么其他cpu看到的一定也是这个顺序)
     A=B=0
       cpu 0         cpu 1        cpu2
     write 1->A    read A->R1   
                   write 1->B    read B->R2
                                 read A->R3
        不存在R1=1 && R2=1 && R3=0
x86上阻止读与写之间的乱序：
   -mfence:在这个指令之前的所有的读和写的指令都变成全局可见的。

Linux Kernel中的内存屏障
   -与其他平台相比，特别是alpha(基本上读与读，写与写都可能乱序),x86是一个相对来说比较强序(strong order)的平台, 但是linux kernel服务于各种平台，所以有各种各样的memory barrier。
  -主要的barrier:
    -barrier():用来防止由编译器导致的乱序
    -smp_rmp():所有位于此函数之前的读操作不能越过此函数
    -smp_wmb():所有位于此函数之前的写操作不能越过此函数
    -smp_mb():所有位于此函数的任意读写操作不能越过此函数
    -smp_read_barrier_depends():数据依赖屏障
     e.g:
      read a
      read buffer[a]
     注意与控制依赖的区别：
      read a
      if(a)
        read buffer[a]
    -memory barrier的使用规则
      smp_rmb() VS.smp_wmb() or smp_mb()
      smp_read_barrier_depends()VS. smp_wmb() or smp_mb()
      smp_mb() VS. smp_mb()
    -隐含的屏障:
      -所有的smp_xx()屏障除了smp_read_barrier_depends()都隐含了编译屏障
      -对于有更新操作且返回旧值或新值得原子操作都会隐含全屏障，e.g:xchg()/cmpxchg()/test_and_set_bit()

   Memory barrier VS. LOCK
    -lock()和unlock()不隐含全屏障，它允许上下两端的代码进到了临界区，但不能穿透临界区:e.g
     a=1;            lock();
     lock();         b=2;
     c=3;            c=3;
     unlock();       a=1;
     b=2;            unlock();

   什么时候需要内存屏障:
     -在设计lockless的算法时候，必定要考虑memory barrier
     -在CPU和device之间做IO的时候
   使用内存屏障的一个例子
     kvm的内存虚拟化中，有一个lockless的算法:
     -walk_shadow_page_lockless_begin()与
      walk_shadow_page_locakless_end()之间可以访问页表
     -在释放页表时候，如果vcpu处于GUEST状态，需要发送中断(IPI)给这个VCPU。
     -所以基本思想是，在做lockless访问的时候，将这个CPU的中断禁止，然后将其状态改为处于GUEST的状态。
     为什么这个lockless的算法需要内存屏障呢？他为了防止如下例子的发生。
     CPU0                   CPU1
   Read page table A
   IRQ disable
                         free page table A and see
                         VCPU is not in guest mode
   Set vcpu 0 in guest 
   mode！！！accessing A
   is invalid
      说白了对于walk_shadow_page_lockless_begin就是防止，一个读操作优化到一个写操作前面。 考虑：那么是否此处仅仅使用一个读屏障就行了。 
      那么对于walk_shadow_page_lockless_begin就要防止，mode的修改不被优化到别的写操作之前。可能会出问题


Linux Kernel常用的数据结构
List
- list,hlist,rcu list
RB tree

hlist常用接口
-测试：
 hlist_empyt()
 hlist_unhashed()
-遍历
 hlist_for_each_entry()
 hlist_for_each_entry_safe()

rcu list常用接口
包括：rcu list和rcu hlist <linux/linux/rculist.h>
常用接口：
 -初始化：INIT_LIST_HEAD_RCU();用hlist_first_rcu()来初始化hlist_head
 -读侧：
  读侧需要使用rcu来保护list/hlist
  list_for_each_entry_rcu();hlist_for_each_entry_rcu()
 -写测
  需要自己做并发控制，在释放资源的时候需要使用rcu的同步机制来和读侧进行同步
  list_add_rcu();list_add_tail_rcu();list_del_rcu();list_replace_rcu();list_splice_init_rcu();
  hlist_del_rcu();hlist_replace_rcu();hlist_add_head_rcu();

RB tree
 -RB_entry
 -使用红黑树
   初始化根节点：
      struct  rb_root mytree = RB_ROOT
 -红黑树的搜索，左孩子小于右孩子
 -使用红黑树
   插入节点：利用上述的搜索算法找到要插入的位置然后调用rb_link_node(node, parent, parent, rb_link)将新节点插入到tree，最后调用rb_insert_color(node, root)来配色
  -删除一个节点：rb_erase(victim,root)
  -其他：
   rb_replace_node(old, new, tree)
   rb_fist(tree);rb_last(tree);rb_next();rb_prev();

内存管理：
   -内存初始化
   -memblock(bootmem)分配器
   -page分配器
   -slab分配器

内存初始化：
  -内存布局探测图：E820图
  -E820介绍
   在x86的机器上，由bios提供的中断，中断号是0x15，在调用的时候AX寄存器必须为0xE820，该中断需要连续调用，每次返回一段内存的空间起始地址和大小以及他的属性（可用的RAM or bios保留的）
  -e820详细的用法：
    输入：
     EAX=0xE820
     EBX：用来表示读取信息的Index，初始化为0，中断返回后该寄存器存放下次要获取的信号的需要。
     ES:DI：用来保存信息的buffer
     ECX：buffer的大小
     EDX：签名，必须为"SMAP"
    输出：
     CF：如果flags寄存器中的CF被置位表示调用出错
     EAX：里面返回"SMAP",是否出错
     ES:DI：对应的buffer，里面存放获取到的信息
     ECX：BIOS在buffer中存放的数据大小
     EBX：BIOS返回的下次调用的序号，如果返回为0，则表示无后续信息
    linux kernel中的e820使用：
     -boot阶段，会调用detect_memory()->detect_memory_e820()->e820_print_map()
      注意，bios只提供几种基本的类型，在e820_print_type()会遇到其他的类型，它是调用e820_add_region()添加进的其他几种类型，例如ACPI的memory region

  memblock
   -用于启动阶段的一个简单分配器，它负责page alloc初始化之前的内存分配器管理以及在系统boot阶段满足大内存的请求（请求大小超过page，alloc的最大限制）
   -实现
     所有状态保存在一个全局变量中:(memblock.c)
     static struct memblock_memory_init_regions[INT_MEMBLOCK_REGIONS] __initdata_memblock
     static struct memblock_region memblock_reserved_init_regions[INIT_MEMBLOCK_REGIONS] __initdata_memblock;
    注意： __initdata_memb[E820MAX]lock的修饰，它位于.init段，在不支持memory hotplug的时候，初始化完了就会被释放。
    memblock.memory:表示可用的内存
    memblock.reserved:表示已经分配出去了的内存
    连着都是struct memblock_type的结构（struct memblock_region, struct memblock_type）
 
1)分配给用户的page，里面那个页面来表示，这个页面来自那个node的，cpu怎么访问远端的node呢？（NUMA架构）
2)对于page的cache是怎么能够提升CPU的cache的呢？
